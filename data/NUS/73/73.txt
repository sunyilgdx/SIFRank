Dogs or Robots: Why do Children see them as Robotic Pets rather than Canine Machines?
Abstract
In the not too distant future Intelligent Creatures
(robots, smart devices, smart vehicles, smart buildings
, etc) will share the everyday living environment
of human beings. It is important then to analyze the
attitudes humans are to adopt for interaction with
morphologically different devices, based on their appearance
and behavior. In particular, these devices
will become multi-modal interfaces, with computers
or networks of computers, for a large and complex
universe of applications. Our results show that children
are quickly attached to the word `dog' reflecting
a conceptualization that robots that look like dogs (in
particular SONY Aibo) are closer to living dogs than
they are to other devices. By contrast, adults perceive
Aibo as having stronger similarities to machines than
to dogs (reflected by definitions of robot). Illustration
of the characteristics structured in the definition
of robot are insufficient to convince children Aibo is
closer to a machine than to a dog.
Introduction
The play R. U. R. (Rossum's Universal Robots), written
by the Czech author Karel Capek, was produced
in London in 1923. The term robot entered the English
language (in Czech the word `robota' means
`heavy labor'). The robot concept remained science
fiction until 1961 when Unimation Inc. installed the
world's first industrial robot in the US. Unimation
Inc. made Australia's first robot, installed in 1974.
The emergence of legged autonomous robots and their
commercial release (as in Honda's Asimo and Sony's
Aibo) contribute to support the hypothesis that mobile
robots will soon become common in our everyday
environments. The commercial release of the Personal
Computer (PC) occurred just a generation ago,
yet now it is a common household item. This forecast
has prompted some studies into the acceptabil-Copyright
c 2004, Australian Computer Society, Inc. This paper
appeared at 5th Australasian User Interface Conference
(AUIC2004), Dunedin. Conferences in Research and Practice
in Information Technology, Vol. 28. A. Cockburn, Ed. Reproduction
for academic, not-for profit purposes permitted provided
this text is included.
This work was supported by a Griffith University Research
Grant as part of the project "Robots to guide the blind the
application of physical collaborative autonomous intelligent
agents".
ity and attitudes these artifacts generate among human
beings (Fong, Nourbakhsh & Dautenhahn 2003).
For example, Kahn et al have recently embarked on
a series of studies with children (Kahn Jr., Friedman
, Freier & Severson 2003) and adults (Kahn Jr.,
Friedman & Hagman 2002) investigating matters such
as humans attributing social and ethical stance to
robots like Sony's Aibo. Earlier Bumby and Dautenhahn
(Bumby & Dautenhahn 1999) explored reactions
of children as they interacted with a robot.
Reports have recently appeared in the media of cases
where humans also build emotional attachments to
robots that do not look like animals, similar to those
they have for home pets. An example is the robotic
vacuum cleaners in (Kahney 2003).
While some experts in childhood development argue
that the use of robot-dolls (machines with realism
) in children's environments `cuts off open-ended
imaginative play' there are some studies showing that
intelligent children will still explore beyond the limitations
of the machine. Similar concerns about other
technologies have been also subject of debate. For
example, the concerns about children reducing their
play with other children, or increasingly aggressive
behavior because of computer games, can be attributed
more to exposure to the type of game than to
the technology of computer games themselves (Lawry,
Upitis, Klawe, Anderson, Inkpen, Ndunda, Hsu, Leroux
& Sedighian 1995). Researchers have found that
children (in particular boys) will entertain and seek
more challenging and interesting computer games
(not necessarily violent games) and that there is no
observable increase in violent behavior or deterioration
in social behavior (Lawry et al. 1995).
Recent studies have focused on the attitudes gen-erated
by Sony's Aibo on humans, we propose here
to explore the differences between Dog (as in living
animal) and Robot (as in lifeless machine assembled
from parts) in the concepts and language formations
in children. Naturally, the smaller the difference, the
more it is likely that humans will attribute animal
characteristics (as high up as rights) to a robot. The
question is, `what makes a small or a large difference?'
If the difference is very small, perhaps humans will
interact with autonomous robots as they do with animals
. We suggest that in today's children's world,
the issue is not confusion between reality and fantasy
(Aylett 2002). To a child, Sony's Aibo is not a
fantasy but reality.
Identification of what makes children perceive a
robot as a dog (an animal) or as a robot is important,
especially if one wants to design robots stressing the
difference or diluting it. Our research reveals that the
look and feel of Sony's Aibo and its body shape go
a long way into its acceptability as a dog. Its play-7
ful behavior, tail wagging, legged walk, recovery from
falls, sitting and hand shaking are absorbed into the
child's mind. Later, illustration of its robotic features
are repeatedly insufficient to fully convince the children
that this is an artifact (and not a being with
feelings).
Unless Aibo does something unacceptable for a
dog (like speak with a human voice), it remains essentially
a dog. Our findings that human speech in Aibo
reduces its dog-ness and increases its robot-ness may
be attributed to the `uncanny valley' (Scheeff, Pinto,
Rahardja, Snibbe & Tow 2000). Although we are
not measuring emotional response, we have observed
dissatisfaction with Aibo as a dog, since clearly it is
only humans that talk (although children accept talking
toys and talking animals in fantasy or animated
movies).
The rest of this paper is organized as follows. Section
2 will describe our research methods. Section 3
will elaborate on the findings. Section 4 will present
conclusions and final remarks. Our aim is to explore
and contrast the properties currently accepted in the
definition of `mobile autonomous robot'. The International
Federation of Robotics (IFR) and the Australian
Robot Association follow the ISO standard
vocabulary (ISO 8373) to describe `manipulating industrial
robots operated in a manufacturing environ-ment'
. A robot has three essential characteristics:
1. It possesses some form of mobility (formally, a
robot must possess at least three programmable
axes of motion).
2. It can be programmed to accomplish a large variety
of tasks.
3. After being programmed, it operates automati-cally
.
Mobile robots can move away from a fixed location
and come in two varieties: tethered and autonomous;
a tethered robot may have its power supply or its
control unit overboard, possibly relying on a desktop
computer and a wall outlet and a long cord. Autonomous
mobile robots bring everything along (control
unit, body, actuators, sensors and power supply).
The control unit is typically a computer and software.
Our research attempts to find out if children do indeed
notice these properties or fixate more on the
form and behavior of the artifact.
The methods
This research was performed by a series of demonstrations
of Aibo and other robots, toys and models
. in particular using Lego Mindstorms
1
constructions
(Knudsen 1999), remote control toy cars and
autonomous battery toys.
The demonstrations were conducted with preschool
children as well as those from the first 4 years
of primary school across 3 schools, two childcare centers
, and a museum in the urban area of Brisbane,
Australia. Table 1 summarizes the presentations and
the age groups of children. Whenever consent was
given, a video/or audio of the session was recorded.
Alternatively, a secretary took notes of the statement
made by children. Sessions lasted between 30 minutes
and approximately one hour.
The sessions consisted of five stages.
1. Establishing the language. In the first minutes of
the session, children are asked to describe what
they see. The goal of this stage is to obtain a
vocabulary from the children to discuss the artifacts
that will be presented later.
1
A trademark of the LEGO group.
2. Demonstration of Aibo. In the next 5 to 7 minutes
, a demonstration of Aibo is performed with
one black model without a memory stick, so the
default simple `dog-like' behaviors are in place.
3. Demonstration of the concept of robot. This stage
illustrates the main features that are common in
accepted definitions of a robot. It also ensures
that the children observe that Sony's Aibo shares
these properties with robots.
4. Investigate animal attributes on Aibo. This stage
questions the children for the existence of animal
properties on Sony's Aibo and the justification
for their belief.
5. Challenge Aibo's animal attributes with the other
artifacts used in the session. Children are asked
to confirm or justify that Aibo is a robot. Attempts
are made to convince them of the artificial
nature of Aibo by showing the same property
in an artifact accepted as lifeless and to compel
them to decide on one side of the Dog vs Robot
debate (or generate a new term to describe it).
The initial phase starts with the projection of
a video from RoboCup-2002 legged league (Veloso,
Uther, Fujita, Asada & Kitano 1998) (the video is the
match between the University of Newcastle and Team
Sweden). Presentations at the Powerhouse Museum
in Brisbane consisted of a live match with 8 dogs programmed
as the Mi-PAL Team Griffith participation
in RoboCup-2003. After two minutes the children are
asked to describe what they see in the video. In the
video, human manipulators are visible, which contributes
to the realization that these are real things
and not an animation film. Children are requested to
indicate what the `dogs' are doing (if they suggested
this word, but if they suggest `puppies' then `puppies'
is used). That is, we use the same words the children
themselves have introduced to describe what they see.
Children are then asked to justify why it is a game
of `soccer/rugby' (or whatever word was the most
common or immediate reply).
The phase finishes by bringing an Aibo that is
switched off, placing it on the ground, turning it on,
and waiting. Since Aibo requires some seconds to
`boot' we observe children's reactions and comments.
This phase is obviously different for blind children. It
is replaced by allowing children to explore the robot
with their hands. Blind children still find and recognize
legs, paws, ears, head and tail because of shape,
texture, malleability and movement.
We then proceed to phase two where we illustrate
the default behavior of the Aibo, which includes the
following interactions.
· A couple of fast strokes on its back starts it on
a walk while it makes the sounds of a marching
tune.
· Hard strokes on its head produce sounds and a
red light on its head LEDs.
· Soft strokes on its head produce sounds and a
green light on its LEDs.
· Scratching under its chin produces another set of
sounds and lights.
· Placing it on the floor on its side produces some
sounds, and then Aibo performs a routine to
stand back on its four legs. After getting up,
Aibo shakes, wagging his tail and making other
sounds.
· Presenting a pink ball produces sounds and the
LED on its tail to go pink.
8
School
Level
Children's age
Group size
Boronia Childcare Center
pre-school
4-5
10
Carole Park State School
pre-school
4-5
17
Holland Park State School
3rd year primary
7-8
25
Holland Park State School
1st year primary
5-6
24
Camp Hill State School
1st year primary
5-6
10
Camp Hill State School
1st year primary
5-6
12
Camp Hill State School
1st year primary
5-6
11
Carole Park State School
1st year primary
5-6
22
Carole Park State School
2nd year primary
6-7
24
Carole Park State School
2nd year primary
6-7
28
Carole Park State School
3rd year primary
7-8
26
Carole Park State School
4th year primary
8-9
20
Powerhouse Museum
pre-school
4-5
10
Narbethong State Special School
pre-school (blind)
4-5
3
Table 1: Presentations conducted and age groups.
Figure 1: A 4-legged walking toy with visible battery,
motor and gears. A flexible tail resembles a dog tail.
· Other behaviors that Aibo produces are not directly
triggered by the manipulator. These include
Aibo sitting down, Aibo lying on his stomach
and waving all fours as a synchronized dance,
Aibo waiving one leg, Aibo moving his head from
side to side and flapping his ears.
Children are then invited to interact with Aibo directly
. In particular, to show the pink ball, to produce
the green lights or invite him to walk. They are also
invited to explain what Aibo is doing in their own
words. There are a series of questions that the presenter
goes through as the illustration of behaviors is
performed. These questions are as follows:
· What is Aibo doing now?
· Is he happy or is he sad?
· Does he like to be touched like this?
· Do you think he can get up by himself?
At the completion of this phase, Aibo is turned off
and focus is transferred to other examples of robotics.
Because the commonly accepted definitions of mobile
robots includes that they have their own control unit,
phase three consists of the following:
· A presentation of a 4-legged toy with a tail (made
of a spring) that has a visible battery, motor and
gears (Figure 1). It is illustrated that this toy
needs a battery to operate it and that it has
an on-off-reverse button. Children are asked to
carry out the task of setting it off or stopping
it by taking the battery out. This illustrates
that mobile autonomous robots require power
and carry their source of power.
Figure 2: A model of a humanoid robot.
Figure 3: Remote control car to contrast with the
notion of autonomous control.
· A presentation of a model of a humanoid robot
(Figure 2). Although it looks like a robot, it can
be seen that it has no motors, no batteries and
essentially does nothing.
· A presentation of a remote control car (radio con-trolled
) (Figure 3). This car is also shown to
have batteries on board but all behavior is de-rived
from the actions on the two-lever remote
control. The first lever produces forward or reverse
motion on the back wheels and the second
lever produces left/right turns on the front
wheels. This illustrates the notion of control (remote
and human).
· A Lego Mindstorm construction extremely similar
to `Hank the Bumper Tank' (Knudsen 1999)
(Figure 4). This robot is shown to have a behavior
that allows it to move around and steer away
from obstacles it bumps into (the program is very
similar to the one suggested in (Knudsen 1999,
Chapter 2)). As part of the interactive nature
of the presentation, the children are asked to act
9
Figure 4: A Mindstorm construction with touch and
light sensor.
Figure 5: A Mindstorm construction with touch and
light sensor, that acts on its environment with a mechanical
arm, and plays sounds.
as obstacles for `adapted' Hank. The presenter
points out the sensors behind the robots bumper,
and illustrates that disconnecting these sensors
makes it `unaware' of obstacles.
We also added to Hank a program that used a
light sensor to monitor the color of the ground
beneath it.
This program was similar to the
obstacle avoidance previously mentioned, but
rather than avoid objects it would move away
from dark areas. We presented this behavior as
`being afraid of the dark'. By switching between
these modes, we illustrate that the behavior of
the robot changes with the chosen program.
Using Lego's ROBO-Lab (a graphical programming
application) to build a very simple program
that makes Hank spin in a circle for four seconds,
we show the children its programmable nature.
The children are taken through the process of
building the program, transferring it onto Hank
via an infrared interface and finally running it.
When the program is running, the children are
encouraged to count along, thus verifying that
the program is indeed the one just built. This is
repeated for at least two other timings (around
10 to 20 seconds).
· A Lego construction extremely similar to Minerva
(Knudsen 1999, Chapter 6) was presented
next (Figure 5). The components were shown
to be the same as Hank's and the Lego RCX
is labeled as the `computer control'. A program
similar to the one suggested (Knudsen 1999) produces
the behavior illustrated to the children.
Minerva moves around a white floor until it finds
a black object, uses a robotic arm to pick it up,
then turns around and brings it to another position
close to where it started. It then releases
the object and plays a tune. The presenter en-sured
that the children observed that Minerva
perceives its environment and can act to change
it (thus the notion of actuator is illustrated).
· A series of pictures (or videos) of autonomous
robots were shown to the children. These images
demonstrate that robots come in all sorts
of shapes and sizes. Among these are pictures of
more Aibos, Honda ASIMO, the Sony humanoid
SDX, MINERVA (Thrun, Bennewitz, Burgard,
Cremers, Dellaert, Fox, Hahnel, Rosenberg, Roy,
Schulte & Schulz 1999) and Kismet (Brooks
2002). It was pointed out that robots can produce
smiles, walk, and be as small as a cockroach.
Pictures of experimental robots were shown to
display the wires, gears and components inside
their packaging.
Aibo was then brought back as the presenter repeated
the main concepts, namely:
Aibo requires power and carries a battery. Aibo is
turned on and off. Also, it is shown that Aibo's
behaviors are interrupted and stopped if the battery
is removed.
Aibo has motors. The gears on Aibo's joints, and
wires near its neck are pointed out to the children
.
Aibo has sensors. The strokes on head and sensitivity
to the pink ball are illustrated once more.
Using another pink object (perhaps a piece of
clothing, or the memory stick of Aibo), we show
that the behavior is triggered by the color being
noticed by a sensor and not Aibo understanding
the concept of a ball.
Aibo has actuators and a control program. We install
a memory stick and re-start Aibo. With the
new program it kicks a ball as in the RoboCup
video.
We illustrate Aibo's behavior changes
with different memory sticks.
Once this is completed the next phase commences
by the presenter asking one of the following questions.
1. Does Aibo have feelings?
2. Where does Aibo get energy from?
3. Will Aibo have babies?
Responses of several children were collected. We expected
that this question would have distinct answers
depending on whether we were referring to a robot or
a `living' dog.
We then passed to the final stage. Each time a
child made a response that seemed to indicate animal
essence or animal agency in the Aibo, we chal-lenged
the response. For example, if a child indicated
that Aibo had feelings, we next asked what the child
thinks happens to the feelings when Aibo is turned
off. We found children would continue to support
their point of view. Following the previous example,
many children followed the path that Aibo was just
asleep when turned off. The challenge continued as
the presenter requested children to explain what sort
of feelings Aibo has or if the feelings fade when the
battery runs out. Also, the presenter checked if the
other artifacts, shown before, have feelings and asked
the children to explain why the others do or do not
have those or other feelings.
The sequence of challenges for the 3 questions
above were as follows.
1. Does Aibo have feelings?
· What happens to Aibo's feelings when he is
turned off?
10
Figure 6: The demonstrator with a class of grade 2
children and 3 of the objects: Aibo, Hank and the
4-legged walking toy.
· What happens to his feelings when the battery
runs out?
· What happens to his feelings if we re-move/change/replace
the memory stick and
Aibo`s personality changes?
· What happens to his feelings if Aibo is broken
? Will the feelings come back if we glue
him?
· What feelings do you know Aibo has? How
do you know he is happy/sad?
· Is it possible to pretend to be happy but not
be happy? Do you think Aibo is happy or
just pretending?
2. Where does Aibo get his energy from?
· Where do you get your energy from?
· Where do the other artifacts get their energy
from?
· Does Aibo work without a battery? Do the
others work without a battery?
· What do you think Aibo eats/drinks? Do
you think he needs to visit the toilet?
3. Will Aibo have babies?
· Is Aibo a baby dog? How do you know?
· How will Aibo look after (care for) the babies
?
· Does Aibo need to charge/replace the battery
of the babies?
These paths of questioning were not all developed
ahead of the first presentation. They evolved from
one presentation to the next. Their length reflects
the resistance of the children to change their opinion,
even if all other artifacts have opposite responses to
these questions. That is, for each question, before we
progressed to the next, we confirmed that the children
sustained the notion that a difference remains
between Aibo and the other artifacts. For example,
in the last question sequence, children would start by
confirming that none of the other artifacts can have
babies while Aibo can. When progressing to `Is Aibo
a baby?' and contrasting this with `Is Hank a baby?',
most children realized that Aibo is really like Hank
and cannot have babies.
The findings
After an analysis of the transcript of our videos and
notes we summarize the following findings. It is remarkable
that when we queried the children for their
first impressions of the video we obtained the following
results. To the question `What do you see?' all
sessions had children responding that they saw `dogs'.
This is surprising for two main reasons: firstly the
video shows the robots playing soccer, a behavior not
commonly attributed to dogs. And secondly, the children
would have anticipated seeing robots through
prior conversations with parents and teachers. This
may explain why a few children claimed that the
adults in the video where robots.
As the age of the pupils involved in the study in-creased
, we noticed that the tendency to regard the
robots as `dogs' decreased. The more mature respondents
were more likely to label the robots as `robots'
or `robotic dogs'.
One pupil also gave the more
generic answer of `animals', and another thought that
they were `cats'. Interestingly, on a few occasions
children referred to the humans in the video as the
robots. We believe this is due to their anticipation to
see robots and perhaps the media culture of humanoid
robots.
To the question, `What are they doing?' most children
identified the activity as a game of `soccer'. This
is surprising, since the RoboCup has barriers around
the pitch that make the game more similar to ice-hockey
, and although the robots are legged, they do
not kick the ball with one leg. All robots in this
video kick the ball with two legs simultaneously or
head-butt the ball. The ball is also bright orange,
clearly not a soccer ball. Another point is that although
played in Australia, it is not the most commonly
played sport.
Other suggestions included, `they're fighting',
`playing hockey', and one child thought he was watching
a game of tennis.
Justifications for `why is it a game of soc-cer/football
?' included a rounded ball on the ground,
goals, two teams, referees and goalies.
When initially presenting the Aibo to the children,
rather than give it the label `it', we found that they
would usually use `him' or `her'. Once again this was
more pronounced with younger subjects. As the presenter
went on to explain the attributes of the Aibo
and show its operation, the children while probing
with questions would begin to lose the gender label.
The children generally were of the opinion that the
Aibo did have emotions, with a couple of them claiming
that this was so because it had a `mind'. This
opinion was seemingly an accepted one with many
children declaring at certain stages of the proceedings
that it was either happy or sad.
Upon the exhibition of other robots and robot-like
artifacts, the general consensus was that the Aibo did
in fact meet the criteria for being a robot. However,
the most common term used to describe it was that
of `robotic dog', where dog is the noun. This emphasis
on the dog nature of the robot suggests that the
subjects were still willing to consider it animal-like.
The youngest group, however, needed the most
convincing. They insisted that the Aibo was a dog,
even after repeated demonstrations of its robotic nature
, with the presenter even stating in no uncertain
terms that it was a robot. They did come around
eventually, with one child using the `robotic dog' description
, and his peers following suit.
We briefly describe some reaction to the other objects
. Although initially enthusiastic, children were
quickly disappointed by the model of the humanoid;
mainly its inaction made it uninteresting. One child
said, "it's just a toy, not a robot". The 4-legged walking
toy caused some laughs because it bumps into
things, but children realized rapidly that it did not
offer any `interesting' interaction beside turning it on
and off (potentially reversing the direction). The remote
control car was appealing and children wanted
to play with it even after the presentation. It was
clear to them they were controlling it.
Hank did
11
cause surprise and children wanted to continue playing
with it, or asked about how to program it. Children
wanted to interact with it and explored different
obstacles for its obstacle-backing behavior. On two
occasions we witnessed children convinced that Hank
also had feelings because it was "afraid of the dark".
The mechanical-arm robot caused amazement. We
believe this greater surprise was because children familiar
with Lego do not expect the action of a mechanical
arm lifting an object.
We also performed a variation in our initial approach
to confirm some of these findings. We approached
a different grade 6 class (12 year-olds) that
had been already working with Mindstorm robots and
had done some research assignments on the Internet
and in the library on topics such as `What is a robot?'.
We did a presentation in which the objects were not
necessarily the focus, but the properties of a robot
were the focus. We also demonstrated different applications
of robotics, like using Miranda to assist a blind
person to read a WEB page. The method for collecting
the children's attitudes was a questionnaire of 25
questions asking children to choose between two positions
and to give their reasons for such decisions. We
invited them to reflect on their responses, so they were
asked to answer the questions over a day at school and
at home. The results of 23 answered questionnaires
confirmed that a dog-looking robot rapidly acquires
animalistic properties and values in the minds of children
. In particular, 75% of the children confirmed
that Miranda should be called a `robotic dog' rather
than a `dog-looking robot'. Note that the preferred
noun is dog over robot. The reasons provided in the
questionnaire are illustrative of their thinking: "It has
more dog features than robot features", "Miranda has
characteristics a dog has", "Kinda looks like a real
dog" "It is an automatic dog" and "Just doesn't look
like a dog, she has a dog personality". And on the
question "Does Miranda have feelings?" again 75%
responded positively. Some of the reasons were "She
just isn't a robot. She's almost a real dog", "She can
be happy, unhappy", If you hit her hard, she would
make a noise, but she felt it". Note that in this presentation
we actually changed programs several times,
radically changing the behaviors and personality of
Miranda. Also, real dogs do not talk, but our programs
had a female voice for instructions to kick a
ball and a male voice reading Web pages. Only one
child classified Miranda as a robot because dogs do
not sing.
Discussion and Final Remarks
The blurring of the concept of robotic pet or canine
machine is of interest to us because of the direct applications
of autonomous mobile robots in helping people
. In particular, we foresee that people with disabilities
, the elderly and other groups in need of assistance
, are the first humans that will benefit from
autonomous mobile robots. Naturally, the attitudes,
acceptability and adequate expectations are to match
an effective human-computer interaction. If the person
expects smarter behavior of the robot (things like
gesture/voice recognition) and the technology does
not deliver, then rather than assisting, we will frustrate
the person. It is also important that anyone who
encounters a person assisted by a robot approaches
with attitudes and gestures that allow the robotic
assistant to facilitate the approach. The main motivation
behind this research is a related project on
using Aibo to assist blind people. While it may seem
straightforward that a robotic assistant for the vision
impaired person should be shaped as a dog, this is
not so. Even with guide dogs, other humans find it
difficult to approach and assist a blind person. Humans
expect a strong bond and loyalty of the animal
to its owner, fearing that dogs may misinterpret help
as interfering with the bond, causing then to react
violently.
Our findings agree with those of others (Kahn Jr.
et al. 2002) in that there is a progression of attributes
that humans ascribe to robots like Aibo. This progression
starts from Essence, and advances to Agency,
Social Standing and Moral Standing. Our findings
are that Aibo fulfills biological animistic underpinnings
(children refer to its tail, legs, ears and behaviors
in the same way as for living dogs). It also fulfills
Agency properties (children attribute intentions, feelings
, emotional states, wishes, desires, goals).
We left aside social standing in our methodology,
but strongly suspect that children attribute an emotional
connection and companionship to Aibo. We
observed a clear preference among children for `Do
you want to pat the dog/puppy?' over `Do you want
to touch the robot?'. Many children made unsolicited
comments about how similar it was playing with Aibo
to playing with their dog at home. Similarly, we refrained
from exploring children's attribution of moral
standing to Aibo (for example, should Aibo be punished
for doing something wrong). Nevertheless, we
received unsolicited suggestions that `leaving Aibo
alone or not playing with him would make him sad'
and that `batteries should always be charged, which
may mean more responsibility than for a living dog'.
These types of comments do attribute some rights to
Aibo and a sense that it also deserves some respect.
Our observations indicate that Essence and
Agency are maintained in the child's beliefs even in
the presence and practical illustration of other machines
for which they will not typically attach such
biological or animistic properties, nor psychological
characteristics (although Bob the Builder's cars and
machines talk). In fact, we witnessed arguments and
debates among the children which turned the balance
the other way around, some managing to convince
others that Hank had feelings like `being afraid of the
dark, because afraid is a feeling'.
Also, we found observations that concur with the
writing of anthropologist S. Turkle (Turkle 1999). In
particular, although we did not intend to observe
adults, we witnessed parents and teachers attempting
to convince the children that Aibo was a machine
and not a dog. Some child-carers seem to interpret
our experiment as a lecture on the living versus
the non-living. We believe this reflected some of
Turkle's conclusions about the `thinking about alive-ness'
with older people interpreting machines and
computers through mechanistic/physical interpretations
while the newer generation interprets beings in
computer games and robots as `sort of alive'. Our
best example of this was witnessing a parent selecting
a particular physical argument to convince her
5-year old of `the clear difference' why Aibo is not a
dog. This also pointed out a difference between Aibo
and dogs that we had not observed but that the adult
believed made "the difference". We attempt to illustrate
it with Figure 7. Aibo has one less joint in the
back leg than a dog (the dog, as shown in Figure 7(a),
has hip (1), knee (2), ankle (3) and toes (4)). This
is one degree of freedom less and also the toes bend
back in the dog, while they do not on Aibo. Note
that if we were to choose a physical argument it is
perhaps more obvious that Aibo does not have two
eyes or does not have a wet nose. The point is that
a basic minimum of physical structure is enough to
engage children in a psychological/conceptual interpretation
that then is hard to remove on the basis of
physical evidence.
We believe our results indicate that children are
12
(a)
(b)
Figure 7: A dog (a) has one more degree of freedom
per leg than Aibo (b) and has more movement in the
toes than Aibo.
quickly attached to the notion that `robotic dogs' are
closer to living dogs. Although we would not go as far
as S. Turkle to suggest that `living' has a new meaning
for this generation of children, we suggest that
they will see them as robotic pets more than canine
machines. We expect, therefore, that in the future,
humans will adopt more of them as an interface for
human-computer interaction.
Prof. B. Shneiderman is probably the world's leading
authority in Human-Computer Interaction. He
has repeatedly been outspoken about reducing `ma-chine
intelligence' and `software agents' for building
computers that are more effective tools (Beardsley
1999). At first, our research seems to contradict some
of his ideas; but, interaction with a robot is interaction
with a computer and we agree that it allows
for direct manipulation, even more realistic and perhaps
more meaningful than on the computer screen.
Also, it is now clear that domestic robots will soon
be around us and computers will not be restricted to
output devices like monitors, nor will computers be
confined to fixed locations. Third, we argue that studies
such as ours advance the possibilities of having a
`controllable, consistent and predictable interaction'
with a robot. Thus, we share the vision of interaction
facilitated by proper design. Finally, our aim is
interaction with people who are blind. In such case,
visualization (the coloring of pixels in a monitor) for
`insight' cannot be used. Shneiderman also agrees on
this point. We argue that properly designed robots
will offer a multi-modal interface where insight is com-municated
by embodiment and movement as well as
sound.
Other papers in the literature confirm that people
may develop strong attachments, and even affectionate
relationships with artificial information systems.
Those studies involve human adults on one side and
rather simple emulations of human intelligence in the
other. In such cases, the interface has been rather
simple (or at least not multi-modal), like through a
phone conversation. It is interesting that this may
have both positive and negative outcomes. For example
, as reported in the case of a `Health Behavior Ad-visor
System' (Kaplan, Farzanfar & Friedman 1999),
some patients felt motivated to follow a healthier life
style, while others found it inflicted a sense of guilt
that did not motivate healthier habits. We believe
that understanding people's expectations for robots
is important since these expectations will define the
context for the interactions that may result in effective
use of robotic technology. An example is the potential
attribution of moral standing to robots. This
could eventually regard the robot (and not its manufacturer
) as responsible for its actions. Certainly, this
would have many implications for our society.
Acknowledgments
The authors wish to thank the anonymous referees for
the constructive feedback provided in their reviews.
This work was supported by a Griffith University Research
Grant as part of the project "Robots to guide
the blind - the application of physical collaborative
autonomous intelligent agents".
References
Aylett, B. (2002), ROBOTS -- Bringing intelligent
machines to life?, ABC Books, Sydney NSW,
Australia.
Beardsley, T. (1999), `Humans unite!', Scientific
American March, 35­36. Profile Column.
Brooks, R. (2002), `Humanoid robots', Communications
of the ACM 45(3), 33­38.
Bumby, K. & Dautenhahn, K. (1999), Investigating
children's attitudes towards robots: A case
study, in `Proceedings of the Third Cognitive
Technology Conference, CT'99', M.I.N.D. Lab,
Michigan State University, East Lansing, MI.,
pp. 391­410.
Fong, T., Nourbakhsh, I. & Dautenhahn, K. (2003),
`A survey of socially interactive robots', Robotics
and Autonomous Systems 42, 235­243.
Kahn Jr., P., Friedman, B. & Hagman, J. (2002), I
care about him as a pal: Conceptions of robotic
pets in online Aibo discussion forum, in `Proceedings
of CHI, Interactive Poster: Fun changing
the world, changing ourselves', pp. 632­633.
Kahn Jr., P. J., Friedman, B., Freier, N. & Severson,
R. (2003), Coding manual for children's interactions
with Aibo, the robotic dog -- the preschool
study, Technical Report UW CSE 03-04-03, Department
of Computer Science and Engineering,
University of Washington, Seattle, US.
Kahney,
L.
(2003),
`The
new
pet
craze:
Robovacs',
Wired
Magazine.
June,
16th;
visited
Septenber
10th,
2003,
www.wired.com/news/technology/0,1282,59249,00.html.
Kaplan,
B.,
Farzanfar,
R.
& Friedman,
R.
(1999),
Ethnographic
interviews
to
elicit
patients,
reactions to an intelligent interactive
telephone
health
behavior
advisor
system,
in
M.
N.M.
Lorenzi,
Bethesda,
ed.,
`Proceedings:
AMIA
Symposiu',
American
Medical
Informatics
Association,
www.amia.org/pubs/symposia/D005604.PDF.
Knudsen, J. (1999), The Unofficial Guide to LEGO
MINDSTORM Robots, O'Reilly, Sebastopol,
CA.
13
Lawry, J., Upitis, R., Klawe, M., Anderson, A.,
Inkpen, K., Ndunda, M., Hsu, D., Leroux, S.
& Sedighian, K. (1995), `Exploring common conceptions
about boys and electronic games', Journal
of Computer in Math and Science Teaching
14
(4), 439­459.
Scheeff, M., Pinto, J., Rahardja, K., Snibbe, S. &
Tow, R. (2000), Experiences with Sparky: A social
robot, in `Proceedings of the Workshop on
Interactive Robot Entertainment'.
Thrun, S., Bennewitz, M., Burgard, W., Cremers, A.,
Dellaert, F., Fox, D., Hahnel, D., Rosenberg, C.,
Roy, N., Schulte, J. & Schulz, D. (1999), MINERVA
: A tour-guide robot that learns, in `KI Kunstliche
Intelligenz', pp. 14­26.
Turkle, S. (1999), What are we thinking about when
we are thinking about computers?, in M. Biagi-oli
, ed., `The Science Studies Reader', Routledge,
New York.
Veloso, M., Uther, W., Fujita, M., Asada, M. &
Kitano, H. (1998), Playing soccer with legged
robots, in `In Proceedings of IROS-98, Intelligent
Robots and Systems Conference', Victoria,
Canada.
14
